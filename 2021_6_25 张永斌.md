## DoPrecoding函数分析

### 一.结构体与类定义

#### 1.precoding_mode 

```C++
typedef enum {
    //混合模式：带有浮点计算的定点输入和输出。 最佳定点精度，但不如 BBLIB_FULL_FXP_16B_ACC_MODE 快。 适用于码本和非码本预编码。
    BBLIB_MIXED_MODE, 
    // Full fixed point mode 全定点模式：具有定点计算的定点输入和输出。 比 BBLIB_MIXED_MODE 快，但由于使用 16 位累加而不太准确。 适用于码本预编码。
    BBLIB_FULL_FXP_16B_ACC_MODE,
    //Floating point mode 浮点模式：半精度层数据，所有其他数据单精度。 适用于码本和非码本预编码。
    BBLIB_FLP_MODE, 
}precoding_mode;
```

#### 2.bblib_precoding_5gnr_request

```c++
struct bblib_precoding_5gnr_request
{
    //预编码输入数据结构
    struct bblib_precoding_5gnr_precoding *precoding; 
	//层输入数据结构。
    struct bblib_precoding_5gnr_layers **layers; 
	//预编码模式
    precoding_mode mode; 
};
```

##### bblib_precoding_5gnr_precoding

```c++
//这定义了要使用的波束成形预编码数据。
struct bblib_precoding_5gnr_precoding
{
	//预编码数据以行优先（必须是 64 字节对齐）存储。在浮点模式下：复数浮点数数组 (complex_float*)。在混合模式和全定点模式下：复数 16b 定点数数组
    void *data; 
    //预编码矩阵中的行数。 天线数的有效值为：2、4、8、16。
    uint32_t m_num_antennas; 
	//预编码矩阵中的列数。 给定天线数量的有效层数值为：
	/*	-1, 2 (m_num_antennas = 2);
    	- 1, 2, 4 (m_num_antennas = 4)
        - 1, 2, 4, 8 (m_num_antennas = 8)
        - 1, 8 (m_num_antennas = 16).*/
    uint32_t m_num_layers; 
};
```

##### bblib_precoding_5gnr_layers

```c++
//子载波层的输入数组。 层数将等于预编码参数中指定的层数。 
struct bblib_precoding_5gnr_layers
{
	//IQ 值的数量。
    uint32_t num_values; 
	//层数据（必须是 64 字节对齐）。
    /*
    在浮点模式下：半精度浮点数数组 (complex_half*)。
   	在混合模式下：任何复数 16b 定点数的数组。
  	全定点：任何复数 16b 定点数的数组
    **/
    void *values; 
};
```

####3. bblib_precoding_5gnr_response

```c++
struct bblib_precoding_5gnr_response
{
    //天线输入数据结构
    struct bblib_precoding_5gnr_antennas **antennas; 
};
```

##### bblib_precoding_5gnr_antennas

```c++ 
struct bblib_precoding_5gnr_antennas
{
    //IQ 值的数量。
    uint32_t num_values;
	/*
	天线数据（必须对齐 64 字节）。
    在浮点模式下的复数浮点数数组 (complex_float*)。
    在混合模式下：具有相同输入格式的复数 16b 定点数数组。
    在全定点模式下：具有相同输入格式的复数 16b 定点数数组
	*/
    void *values; 
};
```

### 二.DoPrecoding函数逐步分析

#### 1.模板特例化

```c++
template<typename SIMD_TYPE, typename LAYER_TYPE, 
				precoding_mode k_mode, unsigned k_numAntennas, unsigned k_numLayers>
```

:diamond_shape_with_a_dot_inside:  **参数：**

+ SIMD_TYPE 与 LAYER_TYPE 为模板参数。
+ [k_mode 模式类型](####precoding_mode )
+ k_numAntennas 天线数模
+ k_numLayers 层数

#### 2.函数声明

```c++
void DoPrecoding (const bblib_precoding_5gnr_request *request, bblib_precoding_5gnr_response *response)
```



#### 3.变量定义

```c++
//定义副载波数目
const unsigned numSubCarriers = request->layers[0]->num_values;
//
static constexpr unsigned k_complexValuesPerT = sizeof(SIMD_TYPE) / sizeof(LAYER_TYPE);

//每层或天线的副载波数据必须是一对 SIMD 寄存器的倍数
if (numSubCarriers % k_complexValuesPerT != 0)
    throw std::runtime_error("Sub-carrier count must be a multiple of " + std::to_string(k_complexValuesPerT));

/*
    C++0x中引入了static_assert这个关键字，用来做编译期间的断言，因此叫做静态断言。
    其语法很简单：static_assert(常量表达式，提示字符串)。
    如果第一个参数常量表达式的值为真(true或者非零值)，那么static_assert不做任何事情，就像它不存在一样，否则会产生一条编译错误，错误位置就是该static_assert语句所在行，错误提示就是第二个参数提示字符串。
*/
//天线数必须是 2 的倍数
static_assert(k_numAntennas % 2 == 0, "Number of antennas must be a multiple of 2");
//将request->precoding->data强制转换成复数类型，并赋值给precoding
const std::complex<float>* precoding = reinterpret_cast<const std::complex<float>*>(request->precoding->data);
```

#### 4.for循环进行处理

```c++
//for循环，进行 numSubCarriers/k_complexValuesPerT次
for (unsigned c = 0; c < numSubCarriers; c += k_complexValuesPerT)
    {	//for循环，进行k_numAntennas/2次
        for (unsigned r = 0; r < k_numAntennas; r += 2)
        {
            //定义两个AntennaAccumulator对象
            AntennaAccumulator<SIMD_TYPE, k_complexValuesPerT, k_mode> ant0;
            AntennaAccumulator<SIMD_TYPE, k_complexValuesPerT, k_mode> ant1;

#pragma unroll (k_numLayers)
            for (unsigned i = 0; i < k_numLayers; ++i)
            {
                const std::complex<half>* layers = reinterpret_cast<const std::complex<half>*>(request->layers[i]->values);

                ant0.accumulateLayer ((const uint8_t*)(precoding + (r + 0) * k_numLayers + i), (const uint8_t*)(layers + c));
                ant1.accumulateLayer ((const uint8_t*)(precoding + (r + 1) * k_numLayers + i), (const uint8_t*)(layers + c));
            }
            std::complex<float>* ant0_values = reinterpret_cast<std::complex<float>*>(response->antennas[r + 0]->values);
            std::complex<float>* ant1_values = reinterpret_cast<std::complex<float>*>(response->antennas[r + 1]->values);

            ant0.sumAndWriteBack ((SIMD_TYPE*)(ant0_values + c));
            ant1.sumAndWriteBack ((SIMD_TYPE*)(ant1_values + c));
        }
    }
```

#### AntennaAccumulator对象分析

```c++
//*******************************AntennaAccumulator类解析******************************************
//天线累加器从预编码行和一组副载波层跟踪一个天线的数据值的生成。
template<typename T, unsigned k_complexValuesPerT, precoding_mode k_mode>
struct AntennaAccumulator {};

/* 浮点天线累加器 */
template<typename T, unsigned k_complexValuesPerT>
struct AntennaAccumulator<T, k_complexValuesPerT, BBLIB_FLP_MODE>
{
    /* Default constructors will zero members: T temp0Lower, temp0Upper, temp1Lower, temp1Upper */
    //默认构造函数会将成员归零：T temp0Lower、temp0Upper、temp1Lower、temp1Upper
    AntennaAccumulator () {}

    /* Accumulate the result of multiplying a single precode scalar value by a vector of layer
    //将单个预编码标量值与层向量相乘的结果累加
     * values. Given the existing antenna data this performs:
     *
     *     simd(antData) += scalar(precode) * simd(layer)
     *
     * \param precode A scalar multiplier 一个标量乘数。.
     * \param layer A SIMD layer value stored in half-precision. 以半精度存储的 SIMD 层值。
     */
    void accumulateLayer (const uint8_t* precode, const uint8_t* layer)
    {
        const auto layerRealLower = LoadAndDuplicateReals<T, BBLIB_FLP_MODE>(layer);
        const auto layerImagLower = LoadAndDuplicateImags<T, BBLIB_FLP_MODE>(layer);

        const auto layerRealUpper = LoadAndDuplicateReals<T, BBLIB_FLP_MODE>(layer + sizeof(std::complex<half>) * (k_complexValuesPerT / 2));
        const auto layerImagUpper = LoadAndDuplicateImags<T, BBLIB_FLP_MODE>(layer + sizeof(std::complex<half>) * (k_complexValuesPerT / 2));

        const auto pcAll = BroadcastFirstComplexValue<T, BBLIB_FLP_MODE>(precode);

        temp0Lower = FmAdd(pcAll, layerRealLower, temp0Lower);
        temp0Upper = FmAdd(pcAll, layerRealUpper, temp0Upper);
        temp1Lower = FmAdd(pcAll, layerImagLower, temp1Lower);
        temp1Upper = FmAdd(pcAll, layerImagUpper, temp1Upper);
    }

    /* Generate the final antenna data result from the accumulated data and write it back to the
     * given memory location */
    void sumAndWriteBack (T* dest) const
    {
        dest[0] = AddSub(temp0Lower, SwapRealImag(temp1Lower));
        dest[1] = AddSub(temp0Upper, SwapRealImag(temp1Upper));
    }

    T temp0Lower, temp0Upper, temp1Lower, temp1Upper;
};
```

#### LoadAndDuplicateReals函数分析


```c++
//***********************LoadAndDuplicateReals函数分析****************************
template<typename T, precoding_mode k_mode> 
T LoadAndDuplicateReals (const uint8_t* addr);
template<> inline F32vec8 LoadAndDuplicateReals <F32vec8, BBLIB_FLP_MODE> (const uint8_t* addr)
{
    //将 addr 中的压缩半精度（16 位）浮点元素转换为压缩单精度（32 位）浮点元素
    /*
        FOR j := 0 to 7
            i := j*32
            m := j*16
            dst[i+31:i] := Convert_FP16_To_FP32(a[m+15:m])
    */
    const auto upconv = _mm256_cvtph_ps(*(__m128i*)addr);
    //从 upconv 中复制偶数索引单精度（32 位）浮点元素，并将结果存储在
    /**
        dst[31:0] := a[31:0] 
        dst[63:32] := a[31:0] 
        dst[95:64] := a[95:64] 
        dst[127:96] := a[95:64]
        dst[159:128] := a[159:128] 
        dst[191:160] := a[159:128] 
        dst[223:192] := a[223:192] 
        dst[255:224] := a[223:192]
        dst[MAX:256] := 0
     * */
    return _mm256_moveldup_ps(upconv);
}

template<> inline F32vec16 LoadAndDuplicateReals <F32vec16, BBLIB_FLP_MODE> (const uint8_t* addr)
{
    //将 a 中的压缩半精度（16 位）浮点元素转换为压缩单精度（32 位）浮点元素，并将结果存储在 dst 中。
    /*
    FOR j := 0 to 15
        i := j*32
        m := j*16
        dst[i+31:i] := Convert_FP16_To_FP32(a[m+15:m])
    */
    const F32vec16 upconv = _mm512_cvtph_ps(*(__m256i*)addr);
    //从 a 中复制偶数索引单精度（32 位）浮点元素，并将结果存储在 dst 中。
    return _mm512_moveldup_ps(upconv);
}
template<> inline F32vec8 LoadAndDuplicateReals <F32vec8, BBLIB_MIXED_MODE> (const uint8_t* addr)
{
    /* Gain for scaling Q16s15 in conversion to float number; 2^15 = 32768 */
    //在转换为浮点数时缩放 Q16s15 的增益
    constexpr float gain = 1.0f / 32768.0f;
    //向 dst 的所有元素广播单精度（32 位）浮点值 a。
    /*
        FOR j := 0 to 7
            i := j*32
            dst[i+31:i] := a[31:0]
    */
    const auto scale = _mm256_set1_ps(gain);
    //将 addr 中压缩的 16 位整数符号扩展为压缩的 32 位整数，并将结果存储在 dst 中。
    /*
        FOR j:= 0 to 7
            i := 32*j
            k := 16*j
            dst[i+31:i] := SignExtend32(a[k+15:k])
    */
    const auto upconv = _mm256_cvtepi16_epi32(*(__m128i*)addr);
    //将 a 中的压缩有符号 32 位整数转换为压缩单精度（32 位）浮点元素，并将结果存储在 dst 中。
    /*
    FOR j := 0 to 7
        i := 32*j
        dst[i+31:i] := Convert_Int32_To_FP32(a[i+31:i ])
    */
    const auto flpconv = _mm256_cvtepi32_ps (upconv);
    const auto sflpconv = _mm256_mul_ps(flpconv, scale);
    return _mm256_moveldup_ps(sflpconv);
}
```

#### LoadAndDuplicateReals函数分析

```c++
//*****************************LoadAndDuplicateImags函数分析*********************************8
template<typename T, precoding_mode k_mode> T LoadAndDuplicateImags (const uint8_t* addr);
template<> inline F32vec8 LoadAndDuplicateImags <F32vec8, BBLIB_FLP_MODE> (const uint8_t* addr)
{
    const auto upconv = _mm256_cvtph_ps(*(__m128i*)addr);
    //从 a 复制奇数索引单精度（32 位）浮点元素，并将结果存储在 dst 中。
    /*
        dst[31:0] := a[63:32] 
        dst[63:32] := a[63:32] 
        dst[95:64] := a[127:96] 
        dst[127:96] := a[127:96]
        dst[159:128] := a[191:160] 
        dst[191:160] := a[191:160] 
        dst[223:192] := a[255:224] 
        dst[255:224] := a[255:224]
        dst[MAX:256] := 0
    */
    return _mm256_movehdup_ps(upconv);
}

template<> inline F32vec16 LoadAndDuplicateImags <F32vec16, BBLIB_FLP_MODE> (const uint8_t* addr)
{
    const F32vec16 upconv = _mm512_cvtph_ps(*(__m256i*)addr);
    return _mm512_movehdup_ps(upconv);
}
```
